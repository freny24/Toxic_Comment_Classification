{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEByppWDFzor"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Read JSON file**"
      ],
      "metadata": {
        "id": "UdUW1NYjcx08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "texts = []\n",
        "labels_raw = []\n",
        "\n",
        "with open(\"z639_assignment1_training.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        obj = json.loads(line)\n",
        "        texts.append(obj.get(\"text\", \"\"))\n",
        "        labels_raw.append(obj.get(\"composite_toxic\", None))\n",
        "\n",
        "print(\"First text:\", texts[0])\n",
        "print(\"First label info:\", labels_raw[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdas42D0GFa_",
        "outputId": "e2c4989f-1114-4479-885d-a390185616c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First text: WTF, y'all never made MRE fart balloons in the stumps?\n",
            "\n",
            "Fucking kids these days.\n",
            "First label info: [[False, 74], [True, 323], [False, 1028], [False, 324], [True, 1068]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Convert annotation lists into binary labels**\n",
        "\n"
      ],
      "metadata": {
        "id": "xOe-BiP7dhJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "\n",
        "for comp in labels_raw:\n",
        "    if comp is None:\n",
        "        labels.append(0)   # default to non-toxic if missing\n",
        "        continue\n",
        "\n",
        "    true_count = sum(1 for item in comp if isinstance(item, list) and len(item) > 0 and item[0] is True)\n",
        "    false_count = sum(1 for item in comp if isinstance(item, list) and len(item) > 0 and item[0] is False)\n",
        "\n",
        "    if true_count > false_count:\n",
        "        labels.append(1)\n",
        "    else:\n",
        "        labels.append(0)\n",
        "\n",
        "print(\"First 10 labels:\", labels[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEEgbVHwIXjK",
        "outputId": "dd529452-8d7b-40e1-d167-e2c04582a579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 labels: [0, 0, 1, 1, 0, 0, 0, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Put into a DataFrame**"
      ],
      "metadata": {
        "id": "5ivuRU3XeF4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\"text\": texts, \"label\": labels})\n",
        "print(df.head(10))\n",
        "print(\"Label distribution:\", df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2pajB3QPC1i",
        "outputId": "0b023a84-fb04-4979-b82e-112dbac96b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  WTF, y'all never made MRE fart balloons in the...      0\n",
            "1  No apologies !! McCall has balls !  Ccp is not...      0\n",
            "2  What ever you need to tell yourself to sleep a...      1\n",
            "3                   @exZACKly @CBSNews Fuck off Nazi      1\n",
            "4  Texas is a republican sponsored killing ground...      0\n",
            "5  I get that calling the rapporteur a \"fake job\"...      0\n",
            "6  Ok,  so when are people getting arrested for l...      0\n",
            "7  @noon4s @AndrewJakeMIII @AP @elonmusk MAGA mor...      1\n",
            "8  yeah i doubt that's false. Biden wants Drag qu...      1\n",
            "9  >\\t(unless signed contract exists, which is wh...      0\n",
            "Label distribution: label\n",
            "0    2974\n",
            "1    1026\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split the data**"
      ],
      "metadata": {
        "id": "E1M9L5JweWEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "# assume df exists with columns: \"text\" and \"label\" (from previous step)\n",
        "print(\"Total examples:\", len(df))\n",
        "print(\"Overall label distribution:\", Counter(df['label']))\n",
        "\n",
        "# 60% train, 20% val, 20% test (stratified)\n",
        "train_df, temp_df = train_test_split(df, test_size=0.40, stratify=df['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "print(\"Sizes -> Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n",
        "print(\"Train label dist:\", Counter(train_df['label']))\n",
        "print(\"Val label dist:\",   Counter(val_df['label']))\n",
        "print(\"Test label dist:\",  Counter(test_df['label']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ajOhFePIqc",
        "outputId": "3feb2763-b05a-4b2e-e868-594226d6a214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total examples: 4000\n",
            "Overall label distribution: Counter({0: 2974, 1: 1026})\n",
            "Sizes -> Train: 2400 Val: 800 Test: 800\n",
            "Train label dist: Counter({0: 1784, 1: 616})\n",
            "Val label dist: Counter({0: 595, 1: 205})\n",
            "Test label dist: Counter({0: 595, 1: 205})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF-IDF + Logistic Regression baseline**"
      ],
      "metadata": {
        "id": "ANrBRVdOed8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# 1) Build TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words='english')\n",
        "X_train = tfidf.fit_transform(train_df['text'].astype(str).values)\n",
        "X_val   = tfidf.transform(val_df['text'].astype(str).values)\n",
        "X_test  = tfidf.transform(test_df['text'].astype(str).values)\n",
        "\n",
        "# 2) Train Logistic Regression (class_weight balanced to help with imbalance)\n",
        "clf = LogisticRegression(max_iter=400, class_weight='balanced', random_state=42)\n",
        "clf.fit(X_train, train_df['label'].values)\n",
        "\n",
        "# 3) Evaluate on validation set\n",
        "val_preds = clf.predict(X_val)\n",
        "print(\"Validation set metrics:\")\n",
        "print(classification_report(val_df['label'], val_preds, digits=4))\n",
        "print(\"Accuracy (val):\", accuracy_score(val_df['label'], val_preds))\n",
        "\n",
        "# 4) Evaluate on test set\n",
        "test_preds = clf.predict(X_test)\n",
        "print(\"\\nTest set metrics:\")\n",
        "print(classification_report(test_df['label'], test_preds, digits=4))\n",
        "print(\"Accuracy (test):\", accuracy_score(test_df['label'], test_preds))\n",
        "\n",
        "# 5) show top features for toxic class\n",
        "feature_names = np.array(tfidf.get_feature_names_out())\n",
        "coefs = clf.coef_[0]\n",
        "top_pos = np.argsort(coefs)[-20:][::-1]\n",
        "top_neg = np.argsort(coefs)[:20]\n",
        "print(\"\\nTop tokens predicting TOXIC:\")\n",
        "print(feature_names[top_pos])\n",
        "print(\"\\nTop tokens predicting NON-TOXIC:\")\n",
        "print(feature_names[top_neg])\n",
        "\n",
        "# 6) Save the vectorizer and model for later use\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.joblib')\n",
        "joblib.dump(clf, 'logreg_toxic_baseline.joblib')\n",
        "print(\"\\nSaved tfidf_vectorizer.joblib and logreg_toxic_baseline.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBN_DMVSRhju",
        "outputId": "4d8ca63c-ebf3-418f-debb-da038f765c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8108    0.8067    0.8088       595\n",
            "           1     0.4471    0.4537    0.4504       205\n",
            "\n",
            "    accuracy                         0.7163       800\n",
            "   macro avg     0.6290    0.6302    0.6296       800\n",
            "weighted avg     0.7176    0.7163    0.7169       800\n",
            "\n",
            "Accuracy (val): 0.71625\n",
            "\n",
            "Test set metrics:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8311    0.8185    0.8247       595\n",
            "           1     0.4953    0.5171    0.5060       205\n",
            "\n",
            "    accuracy                         0.7412       800\n",
            "   macro avg     0.6632    0.6678    0.6653       800\n",
            "weighted avg     0.7450    0.7412    0.7430       800\n",
            "\n",
            "Accuracy (test): 0.74125\n",
            "\n",
            "Top tokens predicting TOXIC:\n",
            "['fucking' 'stupid' 'fuck' 'morons' 'shit' 'idiot' 'trash' 'dumb' 'moron'\n",
            " 'ass' 'losers' 'idiots' 'bitch' 'hate' 'bunch' 'black' 'rapist' 'little'\n",
            " 'cock' 'deserves']\n",
            "\n",
            "Top tokens predicting NON-TOXIC:\n",
            "['time' 'probably' 'russia' 'right' 'government' 'world' 'law'\n",
            " 'washingtonpost' 'new' 'com' 'year' 'think' 'yes' 'lot' 'wonder' 'thats'\n",
            " 'good' 'need' 'aren' 'ukraine']\n",
            "\n",
            "Saved tfidf_vectorizer.joblib and logreg_toxic_baseline.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BERT MODEL**"
      ],
      "metadata": {
        "id": "xNkgFX_9esnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (BertTokenizer, BertForSequenceClassification,\n",
        "                          TrainingArguments, Trainer)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Load tokenizer and model\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "\n",
        "# 2. PyTorch Dataset wrapper\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts.reset_index(drop=True)\n",
        "        self.labels = labels.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self): return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts.iloc[idx])\n",
        "        label = int(self.labels.iloc[idx])\n",
        "        enc = self.tokenizer(\n",
        "            text, truncation=True, padding='max_length',\n",
        "            max_length=self.max_length, return_tensors='pt'\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "train_dataset = ToxicDataset(train_df['text'], train_df['label'], tokenizer)\n",
        "val_dataset   = ToxicDataset(val_df['text'],   val_df['label'],   tokenizer)\n",
        "test_dataset  = ToxicDataset(test_df['text'],  test_df['label'],  tokenizer)\n",
        "\n",
        "# 3. Metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
        "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
        "        \"f1\": f1_score(labels, preds, zero_division=0)\n",
        "    }\n",
        "\n",
        "# 4. Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_toxic_checkpoints\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,   # reduce if OOM\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_total_limit=2,\n",
        "    fp16=True,   # mixed precision for speed on GPU\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# 5. Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 6. Train\n",
        "train_result = trainer.train()\n",
        "trainer.save_model(\"./bert_toxic_model\")\n",
        "print(\"Training done.\")\n",
        "\n",
        "# 7. Evaluate on test set\n",
        "metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Test metrics:\", metrics)\n",
        "\n",
        "# 8. Sample predictions\n",
        "samples = [\n",
        "    \"You are the worst person I've ever met.\",\n",
        "    \"Thanks a lot, that helped me so much!\",\n",
        "    \"I can't believe you think that, pathetic.\",\n",
        "    \"Fantastic explanation — learned a lot.\"\n",
        "]\n",
        "enc = tokenizer(samples, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "if torch.cuda.is_available(): model.cuda()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**{k:v.to(model.device) for k,v in enc.items()})\n",
        "    preds = outputs.logits.argmax(axis=-1).cpu().numpy()\n",
        "\n",
        "for s,p in zip(samples, preds):\n",
        "    print(f\"TEXT: {s}\\nPRED: {p} ({'toxic' if p==1 else 'not toxic'})\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "RxAraZKrVcU5",
        "outputId": "0a5db28c-f232-4f57-e421-86849c373249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-244998719.py:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfnfren\u001b[0m (\u001b[33mahujaar-indiana-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250928_220645-dioozc7h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ahujaar-indiana-university/huggingface/runs/dioozc7h' target=\"_blank\">peach-deluge-1</a></strong> to <a href='https://wandb.ai/ahujaar-indiana-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ahujaar-indiana-university/huggingface' target=\"_blank\">https://wandb.ai/ahujaar-indiana-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ahujaar-indiana-university/huggingface/runs/dioozc7h' target=\"_blank\">https://wandb.ai/ahujaar-indiana-university/huggingface/runs/dioozc7h</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [450/450 03:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.529300</td>\n",
              "      <td>0.435322</td>\n",
              "      <td>0.796250</td>\n",
              "      <td>0.599057</td>\n",
              "      <td>0.619512</td>\n",
              "      <td>0.609113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.341000</td>\n",
              "      <td>0.498196</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>0.622754</td>\n",
              "      <td>0.507317</td>\n",
              "      <td>0.559140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.214700</td>\n",
              "      <td>0.541150</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.583784</td>\n",
              "      <td>0.526829</td>\n",
              "      <td>0.553846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test metrics: {'eval_loss': 0.43805167078971863, 'eval_accuracy': 0.7825, 'eval_precision': 0.5720930232558139, 'eval_recall': 0.6, 'eval_f1': 0.5857142857142857, 'eval_runtime': 2.0769, 'eval_samples_per_second': 385.181, 'eval_steps_per_second': 12.037, 'epoch': 3.0}\n",
            "TEXT: You are the worst person I've ever met.\n",
            "PRED: 0 (not toxic)\n",
            "\n",
            "TEXT: Thanks a lot, that helped me so much!\n",
            "PRED: 0 (not toxic)\n",
            "\n",
            "TEXT: I can't believe you think that, pathetic.\n",
            "PRED: 1 (toxic)\n",
            "\n",
            "TEXT: Fantastic explanation — learned a lot.\n",
            "PRED: 0 (not toxic)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediction CSV**"
      ],
      "metadata": {
        "id": "rZ3f3sULe_u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load the test JSON\n",
        "test_path = \"z639_assignment1_test.json\"\n",
        "platform_ids = []\n",
        "texts = []\n",
        "\n",
        "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        obj = json.loads(line)\n",
        "        platform_ids.append(obj[\"platform_id\"])\n",
        "        texts.append(obj[\"text\"])\n",
        "\n",
        "print(\"Loaded\", len(platform_ids), \"test comments\")\n",
        "\n",
        "# 2. Run trained model (e.g., BERT) on test texts\n",
        "enc = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(texts), 32):  # batch size 32 for efficiency\n",
        "        batch = {k: v[i:i+32].to(model.device) for k,v in enc.items()}\n",
        "        logits = model(**batch).logits\n",
        "        batch_preds = logits.argmax(axis=-1).cpu().numpy()\n",
        "        preds.extend(batch_preds)\n",
        "\n",
        "# 3. Convert 0/1 to true/false\n",
        "preds_bool = [\"true\" if p==1 else \"false\" for p in preds]\n",
        "\n",
        "# 4. Make submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    \"platform_id\": platform_ids,\n",
        "    \"prediction\": preds_bool\n",
        "})\n",
        "\n",
        "# 5. Save as CSV\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Saved submission.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu9UmFqaV9_s",
        "outputId": "fe0f6641-0142-4240-9763-38b454b91f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 500 test comments\n",
            "Saved submission.csv\n"
          ]
        }
      ]
    }
  ]
}